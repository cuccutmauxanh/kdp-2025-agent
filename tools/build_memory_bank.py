"""
Build Memory Bank - X√¢y d·ª±ng ChromaDB t·ª´ Obsidian Vault
======================================================

Script n√†y s·∫Ω ƒë·ªçc t·∫•t c·∫£ notes t·ª´ Obsidian Vault v√† t·∫°o ChromaDB collection
ƒë·ªÉ AI agent c√≥ th·ªÉ query knowledge m·ªôt c√°ch hi·ªáu qu·∫£.
"""

import chromadb
import json
import logging
from pathlib import Path
from typing import List, Dict, Any
import os

# Setup logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class MemoryBankBuilder:
    """
    Builder ƒë·ªÉ t·∫°o ChromaDB Memory Bank t·ª´ Obsidian Vault
    """
    
    def __init__(self, vault_path: str = "vault", db_path: str = "data/memory_bank"):
        """
        Kh·ªüi t·∫°o Memory Bank Builder
        
        Args:
            vault_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn Obsidian Vault
            db_path: ƒê∆∞·ªùng d·∫´n ƒë·∫øn ChromaDB
        """
        self.vault_path = Path(vault_path)
        self.db_path = Path(db_path)
        self.client = None
        self.collection = None
        
        # T·∫°o th∆∞ m·ª•c n·∫øu ch∆∞a c√≥
        self.db_path.mkdir(parents=True, exist_ok=True)
        
        logger.info("üèóÔ∏è Memory Bank Builder ƒë√£ ƒë∆∞·ª£c kh·ªüi t·∫°o")
    
    def connect_to_chromadb(self) -> None:
        """K·∫øt n·ªëi v·ªõi ChromaDB"""
        try:
            self.client = chromadb.PersistentClient(path=str(self.db_path))
            logger.info("‚úÖ ƒê√£ k·∫øt n·ªëi v·ªõi ChromaDB")
        except Exception as e:
            logger.error(f"‚ùå L·ªói k·∫øt n·ªëi ChromaDB: {e}")
            raise
    
    def create_or_get_collection(self, collection_name: str = "kdp_knowledge") -> None:
        """T·∫°o ho·∫∑c l·∫•y collection"""
        try:
            # Th·ª≠ l·∫•y collection hi·ªán c√≥
            self.collection = self.client.get_collection(collection_name)
            logger.info(f"üìÇ ƒê√£ l·∫•y collection: {collection_name}")
        except:
            # T·∫°o collection m·ªõi
            self.collection = self.client.create_collection(
                name=collection_name,
                metadata={"description": "KDP 2025 Knowledge Base"}
            )
            logger.info(f"üÜï ƒê√£ t·∫°o collection m·ªõi: {collection_name}")
    
    def read_markdown_files(self) -> List[Dict[str, Any]]:
        """
        ƒê·ªçc t·∫•t c·∫£ markdown files t·ª´ vault
        
        Returns:
            List c√°c documents v·ªõi metadata
        """
        documents = []
        
        # T√¨m t·∫•t c·∫£ .md files
        md_files = list(self.vault_path.rglob("*.md"))
        logger.info(f"üìÅ T√¨m th·∫•y {len(md_files)} markdown files")
        
        for file_path in md_files:
            try:
                # ƒê·ªçc content
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # T·∫°o metadata
                relative_path = file_path.relative_to(self.vault_path)
                metadata = {
                    "source": str(relative_path),
                    "file_type": "markdown",
                    "category": self._get_category_from_path(relative_path),
                    "size": len(content)
                }
                
                # T√°ch content th√†nh chunks nh·ªè h∆°n
                chunks = self._split_content(content, max_length=1000)
                
                for i, chunk in enumerate(chunks):
                    doc_id = f"{relative_path}_{i}"
                    documents.append({
                        "id": doc_id,
                        "content": chunk,
                        "metadata": {**metadata, "chunk_index": i}
                    })
                
                logger.info(f"üìÑ ƒê√£ x·ª≠ l√Ω: {relative_path} -> {len(chunks)} chunks")
                
            except Exception as e:
                logger.error(f"‚ùå L·ªói ƒë·ªçc file {file_path}: {e}")
        
        return documents
    
    def _get_category_from_path(self, relative_path: Path) -> str:
        """L·∫•y category t·ª´ ƒë∆∞·ªùng d·∫´n file"""
        parts = relative_path.parts
        
        if len(parts) == 0:
            return "root"
        
        # Map folder names to categories
        category_map = {
            "00-META": "meta",
            "01-RESEARCH": "research", 
            "02-PLANNING": "planning",
            "03-DEVELOPMENT": "development",
            "04-TOOLS": "tools"
        }
        
        return category_map.get(parts[0], "other")
    
    def _split_content(self, content: str, max_length: int = 1000) -> List[str]:
        """
        T√°ch content th√†nh c√°c chunks nh·ªè h∆°n
        
        Args:
            content: Content g·ªëc
            max_length: ƒê·ªô d√†i t·ªëi ƒëa m·ªói chunk
            
        Returns:
            List c√°c chunks
        """
        if len(content) <= max_length:
            return [content]
        
        chunks = []
        current_chunk = ""
        
        # T√°ch theo paragraphs
        paragraphs = content.split('\n\n')
        
        for paragraph in paragraphs:
            if len(current_chunk) + len(paragraph) > max_length:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = paragraph
            else:
                current_chunk += "\n\n" + paragraph if current_chunk else paragraph
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks
    
    def ingest_documents(self, documents: List[Dict[str, Any]]) -> None:
        """
        Ingest documents v√†o ChromaDB
        
        Args:
            documents: List documents c·∫ßn ingest
        """
        if not documents:
            logger.warning("‚ö†Ô∏è Kh√¥ng c√≥ documents ƒë·ªÉ ingest")
            return
        
        try:
            # Chu·∫©n b·ªã data
            ids = [doc["id"] for doc in documents]
            contents = [doc["content"] for doc in documents]
            metadatas = [doc["metadata"] for doc in documents]
            
            # Ingest v√†o collection
            self.collection.add(
                ids=ids,
                documents=contents,
                metadatas=metadatas
            )
            
            logger.info(f"‚úÖ ƒê√£ ingest {len(documents)} documents v√†o ChromaDB")
            
        except Exception as e:
            logger.error(f"‚ùå L·ªói ingest documents: {e}")
            raise
    
    def build_memory_bank(self) -> Dict[str, Any]:
        """
        X√¢y d·ª±ng to√†n b·ªô Memory Bank
        
        Returns:
            Dict ch·ª©a th·ªëng k√™
        """
        logger.info("üöÄ B·∫Øt ƒë·∫ßu x√¢y d·ª±ng Memory Bank...")
        
        # K·∫øt n·ªëi ChromaDB
        self.connect_to_chromadb()
        
        # T·∫°o collection
        self.create_or_get_collection()
        
        # ƒê·ªçc documents
        documents = self.read_markdown_files()
        
        # Ingest documents
        self.ingest_documents(documents)
        
        # L·∫•y th·ªëng k√™
        stats = self.get_stats()
        
        logger.info("üéâ Ho√†n th√†nh x√¢y d·ª±ng Memory Bank!")
        return stats
    
    def get_stats(self) -> Dict[str, Any]:
        """L·∫•y th·ªëng k√™ v·ªÅ Memory Bank"""
        try:
            count = self.collection.count()
            return {
                "total_documents": count,
                "collection_name": "kdp_knowledge",
                "db_path": str(self.db_path),
                "vault_path": str(self.vault_path),
                "status": "ready"
            }
        except Exception as e:
            return {"error": f"L·ªói l·∫•y stats: {e}"}


def main():
    """Main function"""
    builder = MemoryBankBuilder()
    
    try:
        stats = builder.build_memory_bank()
        print("\nüìä Memory Bank Statistics:")
        print(json.dumps(stats, ensure_ascii=False, indent=2))
        
    except Exception as e:
        logger.error(f"‚ùå L·ªói x√¢y d·ª±ng Memory Bank: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main()) 