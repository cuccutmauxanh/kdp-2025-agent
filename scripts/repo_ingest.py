"""
Repository Ingester
Script ƒë·ªÉ clone v√† ph√¢n t√≠ch c√°c repositories tham kh·∫£o
T·ª± ƒë·ªông t·∫°o research notes trong Obsidian Vault
"""

import os
import subprocess
import requests
from pathlib import Path
from bs4 import BeautifulSoup
import json
from datetime import datetime
import sys

# Add tools directory to path
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'tools'))
from obsidian_writer import ObsidianWriter

class RepoIngester:
    """Tool ƒë·ªÉ ingest v√† ph√¢n t√≠ch repositories"""
    
    def __init__(self):
        self.writer = ObsidianWriter()
        self.repos = {
            "MiniMax-M1": {
                "url": "https://github.com/MiniMax-AI/MiniMax-M1.git",
                "type": "git"
            },
            "Archon": {
                "url": "https://github.com/coleam00/Archon.git", 
                "type": "git"
            },
            "Claude-Task-Master": {
                "url": "https://github.com/eyaltoledano/claude-task-master.git",
                "type": "git"
            },
            "MCP-Protocol": {
                "url": "https://github.com/modelcontextprotocol/python-sdk.git",
                "type": "git"
            },
            "10x-Tool-Calls": {
                "url": "https://github.com/perrypixel/10x-Tool-Calls.git",
                "type": "git"
            },
            "Agent-Zero": {
                "url": "https://github.com/frdel/agent-zero.git",
                "type": "git"
            },
            "Cursor-Best-Practices": {
                "url": "https://github.com/sanjeed5/awesome-cursor-rules-mdc.git",
                "type": "git"
            },
            "Pydantic-Validation": {
                "url": "https://ai.pydantic.dev/",
                "type": "website"
            }
        }
        self.temp_dir = Path("temp_repos")
        self.temp_dir.mkdir(exist_ok=True)
    
    def clone_repo(self, name: str, url: str) -> str:
        """Clone repository v·ªÅ local"""
        repo_path = self.temp_dir / name
        
        if repo_path.exists():
            print(f"üìÅ Repo {name} ƒë√£ t·ªìn t·∫°i, skip clone")
            return str(repo_path)
        
        print(f"üì• ƒêang clone {name}...")
        try:
            subprocess.run(["git", "clone", url, str(repo_path)], check=True)
            print(f"‚úÖ ƒê√£ clone th√†nh c√¥ng {name}")
            return str(repo_path)
        except subprocess.CalledProcessError as e:
            print(f"‚ùå L·ªói khi clone {name}: {e}")
            return None
    
    def extract_readme(self, repo_path: str) -> str:
        """Tr√≠ch xu·∫•t n·ªôi dung README"""
        readme_files = ["README.md", "README.txt", "readme.md", "README.rst"]
        
        for readme in readme_files:
            readme_path = Path(repo_path) / readme
            if readme_path.exists():
                try:
                    with open(readme_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        print(f"üìñ ƒê√£ ƒë·ªçc README: {readme}")
                        return content
                except UnicodeDecodeError:
                    try:
                        with open(readme_path, 'r', encoding='latin-1') as f:
                            content = f.read()
                            print(f"üìñ ƒê√£ ƒë·ªçc README (latin-1): {readme}")
                            return content
                    except:
                        continue
        
        print(f"‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y README trong {repo_path}")
        return "Kh√¥ng t√¨m th·∫•y README"
    
    def analyze_structure(self, repo_path: str) -> str:
        """Ph√¢n t√≠ch c·∫•u tr√∫c th∆∞ m·ª•c"""
        structure = []
        repo_path_obj = Path(repo_path)
        
        # B·ªè qua c√°c th∆∞ m·ª•c kh√¥ng c·∫ßn thi·∫øt
        ignore_dirs = {'.git', '__pycache__', 'node_modules', '.vscode', '.idea'}
        
        for root, dirs, files in os.walk(repo_path):
            # L·ªçc b·ªè c√°c th∆∞ m·ª•c kh√¥ng c·∫ßn thi·∫øt
            dirs[:] = [d for d in dirs if d not in ignore_dirs]
            
            level = Path(root).relative_to(repo_path_obj).parts
            indent = '  ' * len(level)
            
            if level:
                structure.append(f"{indent}üìÅ {level[-1]}/")
            
            # Ch·ªâ hi·ªÉn th·ªã m·ªôt s·ªë file quan tr·ªçng
            important_files = [f for f in files if any(f.endswith(ext) for ext in 
                           ['.py', '.js', '.ts', '.md', '.yaml', '.yml', '.json', '.txt'])]
            
            for file in important_files[:10]:  # Gi·ªõi h·∫°n 10 files
                structure.append(f"{indent}  üìÑ {file}")
        
        return "\n".join(structure)
    
    def extract_key_files(self, repo_path: str) -> list:
        """Tr√≠ch xu·∫•t n·ªôi dung c√°c file quan tr·ªçng"""
        key_files = []
        important_extensions = ['.py', '.js', '.ts', '.md', '.yaml', '.yml', '.json']
        repo_path_obj = Path(repo_path)
        
        for root, dirs, files in os.walk(repo_path):
            # B·ªè qua th∆∞ m·ª•c .git
            if '.git' in dirs:
                dirs.remove('.git')
            
            for file in files:
                if any(file.endswith(ext) for ext in important_extensions):
                    file_path = Path(root) / file
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            if len(content) < 5000:  # Gi·ªõi h·∫°n k√≠ch th∆∞·ªõc
                                relative_path = file_path.relative_to(repo_path_obj)
                                key_files.append({
                                    'path': str(relative_path),
                                    'content': content[:1000],  # Gi·ªõi h·∫°n n·ªôi dung
                                    'size': len(content)
                                })
                    except UnicodeDecodeError:
                        try:
                            with open(file_path, 'r', encoding='latin-1') as f:
                                content = f.read()
                                if len(content) < 5000:
                                    relative_path = file_path.relative_to(repo_path_obj)
                                    key_files.append({
                                        'path': str(relative_path),
                                        'content': content[:1000],
                                        'size': len(content)
                                    })
                        except:
                            continue
                    except:
                        continue
        
        # S·∫Øp x·∫øp theo k√≠ch th∆∞·ªõc file (l·ªõn nh·∫•t tr∆∞·ªõc)
        key_files.sort(key=lambda x: x['size'], reverse=True)
        return key_files[:10]  # Ch·ªâ l·∫•y 10 files quan tr·ªçng nh·∫•t
    
    def scrape_website(self, url: str) -> str:
        """Scrape n·ªôi dung t·ª´ website"""
        try:
            response = requests.get(url, timeout=10)
            response.raise_for_status()
            
            soup = BeautifulSoup(response.content, 'html.parser')
            
            # L·∫•y title
            title = soup.find('title')
            title_text = title.get_text() if title else "No title"
            
            # L·∫•y n·ªôi dung ch√≠nh
            main_content = ""
            
            # T√¨m c√°c th·∫ª c√≥ n·ªôi dung quan tr·ªçng
            for tag in soup.find_all(['h1', 'h2', 'h3', 'p', 'code', 'pre']):
                text = tag.get_text().strip()
                if text and len(text) > 10:
                    main_content += f"{text}\n\n"
            
            return f"# {title_text}\n\n{main_content[:2000]}..."
            
        except Exception as e:
            print(f"‚ùå L·ªói khi scrape {url}: {e}")
            return f"Kh√¥ng th·ªÉ truy c·∫≠p {url}: {e}"
    
    def generate_summary(self, name: str, readme: str, structure: str, key_files: list, repo_type: str = "git") -> str:
        """T·∫°o t√≥m t·∫Øt cho repository"""
        today = datetime.now().strftime('%Y-%m-%d')
        
        summary = f"""# Ph√¢n t√≠ch Repository: {name}

## üìã T·ªïng quan
- **Repository**: {name}
- **Type**: {repo_type}
- **Date**: {today}
- **Status**: Completed

## üéØ M·ª•c ti√™u nghi√™n c·ª©u
Ph√¢n t√≠ch ki·∫øn tr√∫c v√† patterns c·ªßa {name} ƒë·ªÉ √°p d·ª•ng v√†o d·ª± √°n KDP-2025-Agent

## üìö N·ªôi dung ch√≠nh

### 1. README Analysis
{readme[:1000]}...

### 2. Project Structure
```
{structure}
```

### 3. Key Files Analysis
"""
        
        for i, file_info in enumerate(key_files[:5], 1):
            file_ext = Path(file_info['path']).suffix
            summary += f"""
#### {i}. {file_info['path']} ({file_info['size']} chars)
```{file_ext[1:] if file_ext else 'text'}
{file_info['content'][:300]}...
```
"""
        
        summary += """
## üí° Key Insights
- [C·∫ßn ph√¢n t√≠ch th√™m d·ª±a tr√™n n·ªôi dung]

## üîó Connections
- Related to: [[Agent Architecture]]
- Similar to: [[Tool Integration]]
- Builds on: [[Core Principles]]

## üìù Implementation Ideas
- [C·∫ßn brainstorm th√™m d·ª±a tr√™n patterns]

## ‚ùì Questions
- [C·∫ßn research th√™m v·ªÅ implementation details]

## üìå Tags
#research #learning #agent-architecture #{{name.lower().replace('-', '-')}}
"""
        
        return summary
    
    def ingest_repo(self, name: str) -> str:
        """X·ª≠ l√Ω to√†n b·ªô repository"""
        print(f"\nüîç B·∫Øt ƒë·∫ßu ingest {name}...")
        
        repo_info = self.repos[name]
        repo_type = repo_info["type"]
        url = repo_info["url"]
        
        if repo_type == "git":
            # Clone repo
            repo_path = self.clone_repo(name, url)
            if not repo_path:
                return None
            
            # Tr√≠ch xu·∫•t th√¥ng tin
            readme = self.extract_readme(repo_path)
            structure = self.analyze_structure(repo_path)
            key_files = self.extract_key_files(repo_path)
            
        elif repo_type == "website":
            # Scrape website
            readme = self.scrape_website(url)
            structure = "Website content"
            key_files = []
        
        # T·∫°o summary
        summary = self.generate_summary(name, readme, structure, key_files, repo_type)
        
        # T·∫°o note trong Obsidian
        note_path = f"01-LEARNING/01-Research-Projects/{name}/Overview.md"
        self.writer.create_note(note_path, summary, template="research-note")
        
        print(f"‚úÖ ƒê√£ t·∫°o note cho {name}: {note_path}")
        
        return note_path
    
    def ingest_all_repos(self):
        """X·ª≠ l√Ω t·∫•t c·∫£ repositories"""
        print("üöÄ B·∫Øt ƒë·∫ßu ingest t·∫•t c·∫£ repositories...")
        
        results = []
        for name in self.repos.keys():
            try:
                result = self.ingest_repo(name)
                results.append((name, result))
            except Exception as e:
                print(f"‚ùå L·ªói khi x·ª≠ l√Ω {name}: {e}")
                results.append((name, None))
        
        # T·∫°o summary report
        self._create_summary_report(results)
        
        print(f"\nüéâ Ho√†n th√†nh ingest {len(results)} repositories!")
        return results
    
    def _create_summary_report(self, results: list):
        """T·∫°o b√°o c√°o t·ªïng h·ª£p"""
        today = datetime.now().strftime('%Y-%m-%d')
        
        report = f"""# Research Summary Report - {today}

## üìä T·ªïng quan
- **Ng√†y nghi√™n c·ª©u**: {today}
- **T·ªïng s·ªë repositories**: {len(results)}
- **Th√†nh c√¥ng**: {len([r for r in results if r[1]])}
- **Th·∫•t b·∫°i**: {len([r for r in results if not r[1]])}

## üìã Chi ti·∫øt t·ª´ng repository

"""
        
        for name, result in results:
            status = "‚úÖ Th√†nh c√¥ng" if result else "‚ùå Th·∫•t b·∫°i"
            report += f"### {name}\n- **Status**: {status}\n- **Note**: {result or 'N/A'}\n\n"
        
        report += """
## üéØ Next Steps
1. Review t·ª´ng research note
2. Extract key patterns v√† insights
3. Apply v√†o KDP-2025-Agent design
4. Update knowledge base

## üìå Tags
#research-summary #learning #kdp-2025
"""
        
        # T·∫°o summary note
        summary_path = f"01-LEARNING/03-Insights/Research-Summary-{today}.md"
        self.writer.create_note(summary_path, report)
        print(f"üìä ƒê√£ t·∫°o summary report: {summary_path}")

# Test function
def test_repo_ingest():
    """Test RepoIngester v·ªõi m·ªôt repository"""
    ingester = RepoIngester()
    
    # Test v·ªõi m·ªôt repo nh·ªè
    result = ingester.ingest_repo("Agent-Zero")
    print(f"Test result: {result}")

if __name__ == "__main__":
    # Test v·ªõi m·ªôt repo tr∆∞·ªõc
    # test_repo_ingest()
    
    # Ingest to√†n b·ªô 8 repositories
    ingester = RepoIngester()
    ingester.ingest_all_repos() 